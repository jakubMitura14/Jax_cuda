Important
https://github.com/ moabarar/qna


better boundary detection
https://arxiv.org/pdf/2210.04285v1.pdf


differentiable augmentations
https://arxiv.org/abs/2010.11695

specialized attention heads 
https://www.researchgate.net/publication/365299392_StyleNAT_Giving_Each_Head_a_New_Perspective

pretreining
https://www.researchgate.net/publication/365486426_Towards_All-in-one_Pre-training_via_Maximizing_Multi-modal_Mutual_Information
https://arxiv.org/abs/2111.14791
https://paperswithcode.com/paper/image-as-a-foreign-language-beit-pretraining


positional encoding
https://arxiv.org/pdf/2107.14222.pdf
https://www.youtube.com/watch?v=vPgZwaIOTgY

Linear transformers
https://arxiv.org/pdf/2105.08399.pdf

Include spacing information !!


BTSwin-Unet: 3D U-shaped Symmetrical Swin Transformer-based Network for Brain Tumor Segmentation with Self-supervised Pre-training
https://link.springer.com/article/10.1007/s11063-022-10919-1
https://ieeexplore.ieee.org/document/9868046

multihead cascaded swin transformers 
https://arxiv.org/pdf/2207.08412.pdf
https://github.com/ayanglab/SwinMR


Loss
https://arxiv.org/abs/2010.01412

optimazation
NadamW - good to check
https://www.google.com/url?sa=t&source=web&rct=j&url=https://arxiv.org/pdf/2211.09760&ved=2ahUKEwjH7Onm3b_8AhVLmIsKHYFVBfoQFnoECC4QAQ&usg=AOvVaw2NeKgrjFUVnJbZ1hDOWM-K
https://www.google.com/url?sa=t&source=web&rct=j&url=https://arxiv.org/pdf/2007.01547&ved=2ahUKEwjhm6_gocD8AhUEx4sKHWH3DB8QFnoECBEQAQ&usg=AOvVaw174yvXW-FB3wtd5qYdRgle



3d swin and 3d deformable detr 
https://github.com/bwittmann/transoar
https://assets.researchsquare.com/files/rs-2102490/v1_covered.pdf?c=1664808117

postprocessing
https://paperswithcode.com/paper/contrastive-learning-rivals-masked-image